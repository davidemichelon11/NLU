{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiMFajtd66UEx+aJQk414w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidemichelon11/NLU/blob/main/NLU_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfoDANvvOpeO"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import subjectivity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('subjectivity')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**BASELINE SUBJECTIVITY**\n",
        "\n"
      ],
      "metadata": {
        "id": "j8oBaoSAM_HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "hDlPJeFxfzpH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc2string(doc):\n",
        "  return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "def sent2string(sent):\n",
        "  return \" \".join([w for w in sent])"
      ],
      "metadata": {
        "id": "KCS54YCW2vdT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "classifier_NB = MultinomialNB()\n",
        "\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]\n",
        "\n",
        "corpus = [sent2string(d[0]).lower() for d in subj_docs] + [sent2string(d[0]).lower() for d in obj_docs]\n",
        "vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "labels = numpy.array(['subj'] * len(subj_docs) + ['obj'] * len(obj_docs))\n",
        "scores = cross_validate(classifier_NB, vectors, labels, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
        "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
        "print(round(average, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQduyIdBM-o6",
        "outputId": "03c59a9f-c855-4824-9d8b-911d2ab4219b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NB and SVM for subj\n",
        "classifier_NB2_subj = MultinomialNB()\n",
        "classifier_SVM_subj = svm.SVC()\n",
        "\n",
        "corpus = [sent2string(d[0]).lower() for d in subj_docs] + [sent2string(d[0]).lower() for d in obj_docs]\n",
        "labels = numpy.array(['subj'] * len(subj_docs) + ['obj'] * len(obj_docs))\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(corpus, labels, test_size=0.3)\n",
        "vectors = vectorizer.fit_transform(train_samples + test_samples)\n",
        "\n",
        "classifier_NB2_subj.fit(vectors[:len(train_samples)], train_labels)\n",
        "labels_pred_NB2 = classifier_NB2_subj.predict(vectors[len(train_labels):])\n",
        "print(classification_report(test_labels, labels_pred_NB2, digits=3))\n",
        "\n",
        "classifier_SVM_subj.fit(vectors[:len(train_samples)], train_labels)\n",
        "labels_pred_SVM = classifier_SVM_subj.predict(vectors[len(train_labels):])\n",
        "print(classification_report(test_labels, labels_pred_SVM, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDE_J5Wjx1V3",
        "outputId": "dd82ab06-e244-4dea-ab70-1cad3c2e4d3a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         obj      0.929     0.902     0.915      1509\n",
            "        subj      0.904     0.930     0.917      1491\n",
            "\n",
            "    accuracy                          0.916      3000\n",
            "   macro avg      0.916     0.916     0.916      3000\n",
            "weighted avg      0.916     0.916     0.916      3000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         obj      0.887     0.875     0.881      1509\n",
            "        subj      0.876     0.887     0.881      1491\n",
            "\n",
            "    accuracy                          0.881      3000\n",
            "   macro avg      0.881     0.881     0.881      3000\n",
            "weighted avg      0.881     0.881     0.881      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BASELINE via SVM - SA**"
      ],
      "metadata": {
        "id": "IhxZwaOvaBcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')\n",
        "mr = movie_reviews\n",
        "neg = mr.paras(categories='neg')\n",
        "pos = mr.paras(categories='pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGeoX7znxAbV",
        "outputId": "0ee1c470-96ba-49e5-be9a-b1986681f3ac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer()\n",
        "classifier_sa = svm.SVC()\n",
        "\n",
        "corpus = [doc2string(p) for p in pos] + [doc2string(n) for n in neg]\n",
        "labels = numpy.array([0] * len(pos) + [1] * len(neg))\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(corpus, labels, test_size=0.1)\n",
        "\n",
        "vectors = vectorizer2.fit_transform(train_samples + test_samples)\n",
        "classifier_sa.fit(vectors[:len(train_samples)], train_labels)\n",
        "labels_pred = classifier_sa.predict(vectors[len(train_labels):])\n",
        "\n",
        "print(classification_report(test_labels, labels_pred, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnx3fdGhcYKX",
        "outputId": "f057c70d-66d4-4459-8229-c7dd4a5619ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.844     0.710     0.772       107\n",
            "           1      0.718     0.849     0.778        93\n",
            "\n",
            "    accuracy                          0.775       200\n",
            "   macro avg      0.781     0.780     0.775       200\n",
            "weighted avg      0.786     0.775     0.775       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each review, remove obj sentences and compute the SVM\n",
        "vectorizer3 = CountVectorizer()\n",
        "classifier_sa2 = svm.SVC()\n",
        "\n",
        "def get_new_rev(original):\n",
        "  new_list = []\n",
        "  for rev in original:\n",
        "    new_rev = []\n",
        "    for s in rev:\n",
        "      vector = vectorizer.transform([sent2string(s)]).toarray()\n",
        "      if classifier_NB2_subj.predict(vector) == ['subj']: \n",
        "        new_rev.append(s)\n",
        "    new_list.append(new_rev)\n",
        "  return new_list\n",
        "              \n",
        "new_pos = get_new_rev(pos)\n",
        "new_neg = get_new_rev(neg)\n",
        "\n",
        "corpus_ = [doc2string(p) for p in new_pos] + [doc2string(n) for n in new_neg]\n",
        "labels_ = numpy.array([0] * len(new_pos) + [1] * len(new_neg))\n",
        "train_samples_, test_samples_, train_labels_, test_labels_ = train_test_split(corpus_, labels_, test_size=0.1)\n",
        "\n",
        "vectors_ = vectorizer3.fit_transform(train_samples_ + test_samples_)\n",
        "classifier_sa2.fit(vectors_[:len(train_samples_)], train_labels_)\n",
        "labels_pred_ = classifier_sa2.predict(vectors_[len(train_labels_):])\n",
        "\n",
        "print(classification_report(test_labels_, labels_pred_, digits=3))\n",
        "counter = 0\n",
        "for i in range(len(test_labels_)):\n",
        "  if (test_labels_[i] - labels_pred_[i]) == 0: counter += 1\n",
        "print('accuracy: ', counter/ len(test_labels_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLGRR3-Q7nuS",
        "outputId": "1e2d9365-5f18-4bcb-bd38-ba34de86a2bc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.869     0.795     0.830       117\n",
            "           1      0.742     0.831     0.784        83\n",
            "\n",
            "    accuracy                          0.810       200\n",
            "   macro avg      0.806     0.813     0.807       200\n",
            "weighted avg      0.816     0.810     0.811       200\n",
            "\n",
            "accuracy:  0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VADER Baseline**"
      ],
      "metadata": {
        "id": "gAm4UxVFiu4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer, VaderConstants"
      ],
      "metadata": {
        "id": "6f80ZdAHf5gU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse complete review\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "labels_vader = numpy.array([0] * len(neg) + [1] * len(pos))\n",
        "prediction_val = [analyzer.polarity_scores(doc2string(v)) for v in (pos + neg)]\n",
        "prediction_labels = [0 if p['pos'] > p['neg'] else 1 for p in prediction_val]\n",
        "\n",
        "print(classification_report(labels_vader, prediction_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPUcrVFXkblr",
        "outputId": "70dbcd39-d82f-4251-96ac-62f44f47f851"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.583     0.842     0.689      1000\n",
            "           1      0.715     0.397     0.511      1000\n",
            "\n",
            "    accuracy                          0.620      2000\n",
            "   macro avg      0.649     0.619     0.600      2000\n",
            "weighted avg      0.649     0.620     0.600      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse each sentence of review, sum sentences contribution as 1\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += 1\n",
        "    else: neg_ += 1\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels_vader, prediction_labels, digits=3))\n",
        "\n",
        "# Analyse each sentence of review, sum sentences contribution as 1\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += p['pos']\n",
        "    else: neg_ += p['neg']\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels, prediction_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGLM9GGPSr4h",
        "outputId": "5c0aff49-eccc-4e55-8153-1ad69849c128"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.698     0.500     0.583      1000\n",
            "           1      0.611     0.784     0.687      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.654     0.642     0.635      2000\n",
            "weighted avg      0.654     0.642     0.635      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.602     0.843     0.702      1000\n",
            "           1      0.738     0.442     0.553      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.670     0.642     0.628      2000\n",
            "weighted avg      0.670     0.642     0.628      2000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}