{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx+9P/VxCfKiYbU2s+oKWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidemichelon11/NLU/blob/main/NLU_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfoDANvvOpeO"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import subjectivity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon' )\n",
        "nltk.download('subjectivity')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "hDlPJeFxfzpH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.cli.download('en_core_web_lg')\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DyA5ZMoGjsv",
        "outputId": "4a8a64f7-8870-46eb-b3e5-b7df27d29264"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def doc2string(doc):\n",
        "  return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "def sent2string(sent):\n",
        "  return \" \".join([w for w in sent])"
      ],
      "metadata": {
        "id": "KCS54YCW2vdT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "def normalizeString(s):\n",
        "  text_tokens = word_tokenize(s)\n",
        "  s = [word for word in text_tokens if not word in stop_words and not word in punctuation]\n",
        "  s = unicodeToAscii(sent2string(s).lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI38_yFDSR6s",
        "outputId": "5df8e6da-8fa9-4f87-d3d0-e3bb2d895b60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]\n",
        "\n",
        "corpus_sub = [normalizeString(sent2string(d[0])) for d in subj_docs] + [normalizeString(sent2string(d[0])) for d in obj_docs]\n",
        "\n",
        "labels_sub = np.array(['subj'] * len(subj_docs) + ['obj'] * len(obj_docs))\n",
        "train_samples_sub, test_samples_sub, train_labels_sub, test_labels_sub = train_test_split(corpus_sub, labels_sub, test_size=0.3)"
      ],
      "metadata": {
        "id": "1yfWeEvbJLeg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Baselines for subjectivity/objectivity detection**\n",
        "\n",
        "Two models have been used:\n",
        "\n",
        "\n",
        "1.   *Naive Bayes Classifier*\n",
        "2.   *Support Vector Machine*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j8oBaoSAM_HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes and NB and SVM for subj\n",
        "classifier_NB_subj = MultinomialNB()\n",
        "classifier_SVM_subj = svm.SVC()\n",
        "vectorizer_sub = CountVectorizer()\n",
        "\n",
        "vectors = vectorizer_sub.fit_transform(train_samples_sub + test_samples_sub)\n",
        "\n",
        "#Multinomial Naive Bayes\n",
        "classifier_NB_subj.fit(vectors[:len(train_samples_sub)], train_labels_sub)\n",
        "labels_pred_NB = classifier_NB_subj.predict(vectors[len(train_labels_sub):])\n",
        "print(classification_report(test_labels_sub, labels_pred_NB, digits=3))\n",
        "\n",
        "#SVM\n",
        "classifier_SVM_subj.fit(vectors[:len(train_samples_sub)], train_labels_sub)\n",
        "labels_pred_SVM = classifier_SVM_subj.predict(vectors[len(train_labels_sub):])\n",
        "print(classification_report(test_labels_sub, labels_pred_SVM, digits=3))"
      ],
      "metadata": {
        "id": "lDE_J5Wjx1V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a4dc24-6e22-4acf-debe-ab93d1f3ca7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         obj      0.922     0.893     0.908      1529\n",
            "        subj      0.893     0.922     0.907      1471\n",
            "\n",
            "    accuracy                          0.907      3000\n",
            "   macro avg      0.908     0.908     0.907      3000\n",
            "weighted avg      0.908     0.907     0.907      3000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         obj      0.863     0.895     0.879      1529\n",
            "        subj      0.886     0.852     0.869      1471\n",
            "\n",
            "    accuracy                          0.874      3000\n",
            "   macro avg      0.875     0.874     0.874      3000\n",
            "weighted avg      0.874     0.874     0.874      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')\n",
        "mr = movie_reviews\n",
        "neg = mr.paras(categories='neg')\n",
        "pos = mr.paras(categories='pos')"
      ],
      "metadata": {
        "id": "NGeoX7znxAbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d46f63-7fda-4c39-f68c-e4eef357e25c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install dataframe-image\n",
        "#distribution of word_length\n",
        "import pandas\n",
        "from collections import Counter\n",
        "\n",
        "lis = []\n",
        "tokens = 0\n",
        "\n",
        "for rev in (subj_docs + obj_docs):\n",
        "  lis.append(len(rev[0]))\n",
        "\n",
        "lis.sort()\n",
        "letter_counts = Counter(lis)\n",
        "\n",
        "i=0\n",
        "lis = set(lis)\n",
        "x_values = []\n",
        "for x in lis:\n",
        "  if i % 10 == 0:\n",
        "    x_values.append(x)\n",
        "  i=i+1\n",
        "\n",
        "df = pandas.DataFrame.from_dict(letter_counts, orient='index')\n",
        "df.plot(kind='bar', color='Black', xticks=x_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "pX0hid1GYwaA",
        "outputId": "42ed91b3-dab9-4763-8d3c-7b6066846ce2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5972d9c6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARSklEQVR4nO3df5BdZX3H8fcXNhCRX5JsU7qbceMEcXA6Ig0/LNORQhWIDqGOP9BaM4qTdiYd6dipUu2MdabthJlOqY4dO5lGG62C+KNN6ghKQezYVnARDJIoBChmIwlr+FXECMRv/7hP6LLZcO/d3bvn7j7v18yde85znj3nu/fe/dyzzz33nMhMJEkL3xFNFyBJmhsGviRVwsCXpEoY+JJUCQNfkiph4EtSJQaaLgBg6dKlOTIy0nQZkjSv3H777T/NzMFO+/dF4I+MjDA6Otp0GZI0r0TEg930d0hHkiph4EtSJQx8SapEX4zhS1JTnnnmGcbGxti/f3/TpRzW4sWLGR4eZtGiRTNaj4EvqWpjY2Mcd9xxjIyMEBFNl3OIzGTfvn2MjY2xYsWKGa3LIR1JVdu/fz9Llizpy7AHiAiWLFkyK/+BGPiSqtevYX/QbNVn4EtSw2644QZOPfVUVq5cyYYNG3q2HQO/SxHR93sDkqbv4N/4bN3aOXDgAOvXr+f6669n+/btXHPNNWzfvr0nv5uBL0kNuu2221i5ciUve9nLOOqoo7jsssvYsmVLT7Zl4E/iHrykubR7926WL1/+3Pzw8DC7d+/uybYMfEmqhIEvSQ0aGhpi165dz82PjY0xNDTUk20Z+DiMI6k5Z555Jvfeey8PPPAATz/9NNdeey2XXHJJT7blN20lqUEDAwN84hOf4MILL+TAgQO85z3v4ZWvfGVvttWTtUrSPJWZc77N1atXs3r16p5vxyEdSaqEgS9JlTDwJakSBr6k6jUxbt+N2arPwJdUtcWLF7Nv376+Df2D58NfvHjxjNflUTqSqjY8PMzY2Bjj4+NNl3JYB694NVMGvqSqLVq0aMZXkpovHNKRpEoY+JJUCQN/hjwPj6T5wsCXpEoY+JJUCQO/DYdsJC0UCzLwDWlJOtSCDHxJ0qEMfEmqhIEvSZWoIvAd05ekLgI/Io6MiDsi4qtlfkVE3BoROyPiCxFxVGk/uszvLMtHelO6JKkb3ezhXwHsmDB/FXB1Zq4EHgUuL+2XA4+W9qtLP0lSwzoK/IgYBt4A/GOZD+B84Euly2bg0jK9psxTll8QjqdIUuM63cP/O+ADwC/L/BLgscx8tsyPAUNlegjYBVCWP176P09ErIuI0YgY7efzUEvSQtE28CPijcDDmXn7bG44Mzdm5qrMXDU4ODibq5YkTaGTC6CcC1wSEauBxcDxwMeAEyNioOzFDwO7S//dwHJgLCIGgBOAfbNeuSSpK2338DPzzzJzODNHgMuAmzPz94BvAm8u3dYCW8r01jJPWX5z9uvFIiWpIjM5Dv+DwPsjYietMfpNpX0TsKS0vx+4cmYlLhyTvw/g9wMkzaWurmmbmbcAt5Tp+4GzpuizH3jLLNQmSZpFVXzTVpJk4EtSNaoM/F6OnTtOL6lfVRn4klQjA1+SKmHgS1IlDHxJqsSCCHw/GJWk9hZE4EuS2jPwJakSBr4kVcLAl6RKGPiSVAkDX5IqYeBLUiUMfEmqhIEvSZUw8CWpEga+JFVi3gT+VBcWkSR1bt4EviRpZgz8PuJZPyX1koEvSZUw8CWpEga+JFXCwJekShj4klQJA1+SKmHgS1IlDHxJqoSBL0mVMPAlqRIGviRVwsCXpEoY+JJUibaBHxGLI+K2iPh+RNwdER8t7Ssi4taI2BkRX4iIo0r70WV+Z1k+Mp3CPHOkJM2uTvbwfwGcn5mvAk4HLoqIc4CrgKszcyXwKHB56X858Ghpv7r00zT4pidpNrUN/Gx5sswuKrcEzge+VNo3A5eW6TVlnrL8gjC1JKlxHY3hR8SREXEn8DBwI3Af8FhmPlu6jAFDZXoI2AVQlj8OLJnNoiVJ3eso8DPzQGaeDgwDZwGvmOmGI2JdRIxGxOj4+PhMVydJaqOro3Qy8zHgm8BrgBMjYqAsGgZ2l+ndwHKAsvwEYN8U69qYmasyc9Xg4OA0y5ckdaqTo3QGI+LEMv0i4HXADlrB/+bSbS2wpUxvLfOU5TdnZs5m0ZKk7g2078LJwOaIOJLWG8R1mfnViNgOXBsRfwncAWwq/TcBn42IncAjwGU9qFuS1KW2gZ+Z24BXT9F+P63x/Mnt+4G3zEp1kqRZ4zdtJakSBr4kVcLAl6RKGPiSVAkDX5IqYeBLUiUMfEmqhIE/j3i6ZEkzYeBLUiUMfEmqhIEvSZUw8CWpEgb+POYHuJK6YeBLUiUMfEmqhIEvSZUw8CWpEga+JFXCwF8gPO2CpHb6JvANLEnqrb4JfElSbxn4klQJA1+SKmHgS1IlDHxJqoSBL0mVMPAlqRIGviRVwsCXpEoY+JJUCQN/gfJUFZImM/AlqRIGviRVwsCXpEoY+JJUCQNfkirRNvAjYnlEfDMitkfE3RFxRWk/KSJujIh7y/1LSntExMcjYmdEbIuIM3r9S0iS2utkD/9Z4E8y8zTgHGB9RJwGXAnclJmnADeVeYCLgVPKbR3wyVmvWpLUtbaBn5kPZeb3yvT/AjuAIWANsLl02wxcWqbXAJ/Jlu8AJ0bEybNeuSSpK12N4UfECPBq4FZgWWY+VBbtAZaV6SFg14QfGyttk9e1LiJGI2J0fHy8y7IlSd3qOPAj4ljgy8AfZ+YTE5dlZgLZzYYzc2NmrsrMVYODg938qCRpGjoK/IhYRCvsP5eZXynNew8O1ZT7h0v7bmD5hB8fLm2SpAZ1cpROAJuAHZn5txMWbQXWlum1wJYJ7e8qR+ucAzw+YehHktSQgQ76nAv8PnBXRNxZ2j4EbACui4jLgQeBt5ZlXwNWAzuBp4B3z2rFkqRpaRv4mflt4HCnXbxgiv4JrJ9hXZplB8+c2Xp6JNXIb9pKUiUMfEmqhIFfKS+QItXHwJekShj4klQJA1+SKmHgS1IlDHwBfogr1cDAl6RKGPiSVAkDX5IqYeBLUiUMfEmqhIEvSZUw8CWpEga+puQx+dLCY+BLUiUMfEmqhIEvSZUw8CWpEga+uuaJ1qT5ycCXpEoY+JJUCQNfbTmEIy0MBr4kVcLAl6RKGPiSVAkDX5IqYeBLUiUMfEmqhIEvSZUw8CWpEga+JFXCwJekShj4klSJtoEfEZ+KiIcj4gcT2k6KiBsj4t5y/5LSHhHx8YjYGRHbIuKMXhYvSepcJ3v4/wRcNKntSuCmzDwFuKnMA1wMnFJu64BPzk6ZkqSZahv4mfkfwCOTmtcAm8v0ZuDSCe2fyZbvACdGxMmzVawkafqmO4a/LDMfKtN7gGVlegjYNaHfWGmTJDVsxh/aZmYC2e3PRcS6iBiNiNHx8fGZliFJamO6gb/34FBNuX+4tO8Glk/oN1zaDpGZGzNzVWauGhwcnGYZkqROTTfwtwJry/RaYMuE9neVo3XOAR6fMPQjSWrQQLsOEXENcB6wNCLGgI8AG4DrIuJy4EHgraX714DVwE7gKeDdPahZkjQNbQM/M99+mEUXTNE3gfUzLUqSNPv8pq1mzIucS/ODgS9JlTDwNevc45f6k4EvSZUw8CWpEga+JFXCwJekShj4klQJA18951E7Un8w8NUo3wykuWPgS1IlDHxJqoSBL0mVMPDVVxzTl3rHwNecMtCl5hj4klQJA1+SKmHgS1IlDHxJqoSBr3nFD32l6TPwJakSBr4kVcLAV1+byRCOwz/S8xn4klQJA18Lhnv00gsz8DWvGfJS5wx8SaqEgS9JlTDwJakSBr4kVcLAlwo/ANZCZ+CrGga6amfgq1rdvAH4ZqGFwMCXpmHyG4BvCJoPDHxJqoSBLx2Ge+xaaHoS+BFxUUT8KCJ2RsSVvdiGNJ845KN+MOuBHxFHAn8PXAycBrw9Ik6b7e1I/axdwL/Q+H+Tp4T2g+yFrRd7+GcBOzPz/sx8GrgWWNOD7UhVaPeG8ELBO5Of7WR5N32n2rbm1kAP1jkE7JowPwacPblTRKwD1pXZJ4EflfbJ/Q47303fGa57aUT8tEfrnum6lgI/7aTvHNf5go/ZHD53M3oufY1NXVs363qh/jMM/ee99it1ajedexH4HcnMjcDGprbfjYgYzcxVTdcxlX6tzbq60691Qf/W1q91zaWIGO2mfy+GdHYDyyfMD5c2SVKDehH43wVOiYgVEXEUcBmwtQfbkSR1YdaHdDLz2Yj4I+DrwJHApzLz7tnezhzr56Gnfq3NurrTr3VB/9bWr3XNpa4eg8jMXhUiSeojftNWkiph4EtSJQx8SaqEgS9JlTDw54mIOCEiNkTEDyPikYjYFxE7StuJDdc2EBF/EBE3RMS2crs+Iv4wIhZZ0yG19eVz2a919XttcyUivhIR74yIY6e7DgN/kj5+YV0HPAqcl5knZeYS4LdL23UN1gXwWeB04C+A1eX2UeBVwD9b0yH69bns17qgv2ubK2cDlwI/jojrIuJ3y3edOuZhmZNExNeBm4HNmbmntP0qsBa4IDNf31BdP8rMKc+b8ULL5kJE3JOZL+92WW01Tdh+Xz6X/VpXu+03XdtciYg7MvPVEXE8rRNSvh04E/gqcE1mfqPdOtzDP9RIZl51MOwBMnNPZl4FvLTBuh6MiA9ExLKDDRGxLCI+yPNPVteERyLiLRHx3OspIo6IiLfR2gOzpufr1+eyX+uC/q5triRAZj6RmZ/NzNXAK4BbgY6uO2LgH6pfX1hvA5YA34qIRyPiEeAW4CTgrQ3WBa3TZ7wZ2BMR90TEPcAe4E1lWZM17S013dsHNR3Ur89lv9YF/V3bXHlyckNm7svMf8jM8ztZgUM6k0TES2i9W64BfqU076V1PqANmdnY3mFEvILWyei+k5lPTmi/KDNvaKquUsPZtPZA7qO11/EaYHtmfq3JugAiYkmZ/FhmvrPRYqYQEb9F6zoSd3Xyb3kP6zgb+GFmPh4Rx9D6OzgDuBv468x8vMHa3gf8S2bWsjd/iIg4mtYb308y898j4h3AbwI7gI2Z+UzbdRj4nYuId2fmpxva9vuA9bSe3NOBKzJzS1n2vcw8o4m6yvY/QusKZwPAjbTC6xbgdcDXM/OvGqhpqhP2nU/r8xky85K5rej/RcRtmXlWmX4vref1X4HXA/+WmRsaqutu4FXlfFgbgZ8BXwYuKO1vaqKuUtvjpZ77gM8DX8zMqs6FHxGfo/U3dgzwGHAs8BVaz09k5tq2K8lMbx3egB83uO27gGPL9AgwSiv0Ae5o+HG5i9aJ8o4BngCOL+0vArY1VNP3aB2Ncx7w2nL/UJl+bcOP1x0Tpr8LDJbpF9Pay2+qrh0TH79Jy+5s+jGjNQT9emATMA7cQOtgiuOarG0OH4Nt5X6A1qjDkWU+Ov07a+wCKP0qIrYdbhGw7DDL5sIRWYZxMvN/IuI84EsR8dJSW5OezcwDwFMRcV9mPgGQmT+PiF82VNMq4Argw8CfZuadEfHzzPxWQ/VMdEQZOjyC1p7ZOEBm/iwinm2wrh9M+C/2+xGxKjNHI+LlQNvhgh7LzPwl8A3gG9H6LsXFtI5U+RtgsMni5sgR5TDMF9PauToBeAQ4GujouyUG/qGWARdy6JEcAfzX3JfznL0RcXpm3gmQmU9GxBuBTwG/3mBdAE9HxDGZ+RTwGwcbI+IEoJHAL+FwdUR8sdzvpX9e7ycAt9N6TWVEnJyZD5Uv1DT55v1e4GMR8ee0Lh343xGxi9bBCu9tsC6Y9Lhka7x6K7C1fN5Qg03AD2n9N/1h4IsRcT9wDq1rh7flGP4kEbEJ+HRmfnuKZZ/PzHc0UBYRMUxrT3rPFMvOzcz/bKCsg9s/OjN/MUX7UuDkzLyrgbIm1/IG4NzM/FDTtRxOCa5lmflAw3UcD6yg9QY5lpl7m6wHICJenpn3NF1H0yLi1wAy8yfli6C/Q2uo+baOft7Al6Q6eBy+JFXCwJekShj4klQJA1+SKmHgS1Il/g/l6ZhMG2ZrFAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baselines for Seniment Analysis**"
      ],
      "metadata": {
        "id": "IhxZwaOvaBcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_sa = CountVectorizer()\n",
        "classifier_sa = svm.SVC()\n",
        "\n",
        "#each element is the review converted to string\n",
        "corpus_sa = [normalizeString(doc2string(p)) for p in pos] + [normalizeString(doc2string(n)) for n in neg]\n",
        "\n",
        "labels_sa = np.array([0] * len(pos) + [1] * len(neg))\n",
        "train_samples_sa, test_samples_sa, train_labels_sa, test_labels_sa = train_test_split(corpus_sa, labels_sa, test_size=0.1)"
      ],
      "metadata": {
        "id": "ewUNWUOvKXPy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM with objective sentences. 73%\n",
        "vectors = vectorizer_sa.fit_transform(train_samples_sa + test_samples_sa)\n",
        "classifier_sa.fit(vectors[:len(train_samples_sa)], train_labels_sa)\n",
        "labels_pred = classifier_sa.predict(vectors[len(train_labels_sa):])\n",
        "\n",
        "print(classification_report(test_labels_sa, labels_pred, digits=3))"
      ],
      "metadata": {
        "id": "Cnx3fdGhcYKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e4d7d0-3a2a-4b70-edf5-ba643cac5622"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.856     0.856     0.856       104\n",
            "           1      0.844     0.844     0.844        96\n",
            "\n",
            "    accuracy                          0.850       200\n",
            "   macro avg      0.850     0.850     0.850       200\n",
            "weighted avg      0.850     0.850     0.850       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_obj_sentences(reviews, vectorizer_sub):\n",
        "  new_list = []\n",
        "  for rev in reviews:\n",
        "    new_rev = []\n",
        "    for s in rev:\n",
        "      vector = vectorizer_sub.transform([sent2string(s)]).toarray()\n",
        "      if classifier_NB_subj.predict(vector) == ['subj']: \n",
        "        new_rev.append(s)\n",
        "    new_list.append(new_rev)\n",
        "  return new_list"
      ],
      "metadata": {
        "id": "i0fw_ujaMF8V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM without obj sentences --> circa 80-82% accuracy\n",
        "# For each review, remove obj sentences and compute the SVM\n",
        "vectorizer_sa_subj = CountVectorizer()\n",
        "classifier_SVM_subj = svm.SVC()\n",
        "\n",
        "new_pos = remove_obj_sentences(pos, vectorizer_sub)\n",
        "new_neg = remove_obj_sentences(neg, vectorizer_sub)\n",
        "\n",
        "corpus_sa_subj = [normalizeString(doc2string(p)) for p in new_pos] + [normalizeString(doc2string(n)) for n in new_neg]\n",
        "\n",
        "labels_sa_subj = np.array([0] * len(new_pos) + [1] * len(new_neg))\n",
        "train_samples_, test_samples_, train_labels_, test_labels_ = train_test_split(corpus_sa_subj, labels_sa_subj, test_size=0.2)\n",
        "\n",
        "vectors_ = vectorizer_sa_subj.fit_transform(train_samples_ + test_samples_)\n",
        "classifier_SVM_subj.fit(vectors_[:len(train_samples_)], train_labels_)\n",
        "labels_pred_ = classifier_SVM_subj.predict(vectors_[len(train_labels_):])\n",
        "\n",
        "print(classification_report(test_labels_, labels_pred_, digits=3))"
      ],
      "metadata": {
        "id": "vLGRR3-Q7nuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6faaf0d4-226a-4a44-9d6d-24addf8c5d75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.809     0.862     0.835       196\n",
            "           1      0.859     0.804     0.830       204\n",
            "\n",
            "    accuracy                          0.833       400\n",
            "   macro avg      0.834     0.833     0.832       400\n",
            "weighted avg      0.834     0.833     0.832       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VADER Baseline**"
      ],
      "metadata": {
        "id": "gAm4UxVFiu4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer, VaderConstants"
      ],
      "metadata": {
        "id": "6f80ZdAHf5gU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse complete review\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "labels_vader = np.array([0] * len(neg) + [1] * len(pos))\n",
        "prediction_val = [analyzer.polarity_scores(doc2string(v)) for v in (pos + neg)]\n",
        "prediction_labels = [0 if p['pos'] > p['neg'] else 1 for p in prediction_val]\n",
        "\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))"
      ],
      "metadata": {
        "id": "EPUcrVFXkblr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88545510-e8a4-4b52-a0c5-45cab89ed202"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.583     0.842     0.689      1000\n",
            "           1      0.715     0.397     0.511      1000\n",
            "\n",
            "    accuracy                          0.620      2000\n",
            "   macro avg      0.649     0.619     0.600      2000\n",
            "weighted avg      0.649     0.620     0.600      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse each sentence of review, sum sentences contribution as 1\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += 1\n",
        "    else: neg_ += 1\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))\n",
        "\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += p['pos']\n",
        "    else: neg_ += p['neg']\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))"
      ],
      "metadata": {
        "id": "JGLM9GGPSr4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab6ca8b-1875-4c7f-ada1-f835ee6ba0b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.698     0.500     0.583      1000\n",
            "           1      0.611     0.784     0.687      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.654     0.642     0.635      2000\n",
            "weighted avg      0.654     0.642     0.635      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.602     0.843     0.702      1000\n",
            "           1      0.738     0.442     0.553      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.670     0.642     0.628      2000\n",
            "weighted avg      0.670     0.642     0.628      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectivity detection using LSTM**"
      ],
      "metadata": {
        "id": "xQLKQjBW62iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "-agqb7wb0Jf8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 120\n",
        "seq_len = 50\n",
        "word_embedding = 300\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "n_hidden = 128\n",
        "n_categories = 2"
      ],
      "metadata": {
        "id": "mY-ln6qufjab"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Db(data.Dataset):\n",
        "  def __init__(self, rev, labels):\n",
        "    self.rev = rev\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.rev)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    return torch.tensor(self.rev[idx]), torch.tensor(self.labels[idx])"
      ],
      "metadata": {
        "id": "F_9zUQ9luN_U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tens(rev, seq_len, word_embedding):\n",
        "  \n",
        "  rev = word_tokenize(rev)\n",
        "  if len(rev) > seq_len: \n",
        "    rev = rev[:seq_len]\n",
        "\n",
        "  sent = []\n",
        "  for i, w in enumerate(rev):\n",
        "    vector = nlp.vocab[w].vector\n",
        "    sent.append(vector.tolist())\n",
        "  \n",
        "  z = list(np.zeros(word_embedding, dtype=np.float32))\n",
        "  zs = [z for each in range(seq_len - len(sent))]\n",
        "  return zs + sent"
      ],
      "metadata": {
        "id": "rpnC4z92-Cki"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.append(np.zeros((len(subj_docs)), dtype=int), np.ones((len(subj_docs)), dtype=int))\n",
        "# corpus = [sent2string(d[0]).lower() for d in subj_docs] + [sent2string(d[0]).lower() for d in obj_docs]\n",
        "\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(corpus_sub, labels, test_size=0.3)\n",
        "\n",
        "train_samples = [create_tens(rev, seq_len, word_embedding) for rev in train_samples]\n",
        "test_samples = [create_tens(rev, seq_len, word_embedding) for rev in test_samples]\n",
        "\n",
        "# train samples are tensors of seq_len x word_embedding\n",
        "train_dataset = Db(train_samples, train_labels)\n",
        "test_dataset = Db(test_samples, test_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "4yYFIJRRPEKt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "def train(model, optimizer, train_loader, e):\n",
        "\n",
        "  cumulative_accuracy = 0\n",
        "  samples=0\n",
        "  pbar = tqdm(train_loader)\n",
        "  for x,y in pbar:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.long())\n",
        "    _, predicted = outputs.max(1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    samples += x.shape[0]\n",
        "    cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "    pbar.set_description('Epoch {}/{}, Train accuracy: {:.2f}'.format(e+1,epochs, cumulative_accuracy/samples*100))\n",
        "  return cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "J196nAnrEXhg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "\n",
        "  cumulative_accuracy = 0\n",
        "  samples=0\n",
        "  pbar = tqdm(test_loader)\n",
        "  for x,y in pbar:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.long())\n",
        "    _, predicted = outputs.max(1)\n",
        "    samples += x.shape[0]\n",
        "    cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "    pbar.set_description('Evaluate accuracy: {:.2f}'.format(cumulative_accuracy/samples*100))\n",
        "  return cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "XIYsC8uDEYAx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on SA: 73%\n",
        "class LSTM_2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM_2, self).__init__()\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.i2h = nn.LSTM(input_size, hidden_size, dropout = 0.5, bidirectional=True, batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.leaky_ReLU = nn.LeakyReLU(0.1)\n",
        "    self.i2o = nn.Linear(2*hidden_size, output_size)\n",
        "      \n",
        "  def forward(self, input, hidden=None, cell=None):\n",
        "    if hidden==None:\n",
        "      hidden = self.init_hidden(input.shape[0])\n",
        "    if cell==None:\n",
        "      cell = self.init_hidden(input.shape[0])\n",
        "\n",
        "    output, (_,_)= self.i2h(input, (hidden,cell))\n",
        "    output = self.dropout(output)\n",
        "    output = self.i2o(output)\n",
        "    output = self.leaky_ReLU(output)\n",
        "    output = output[:, -1]\n",
        "    return output\n",
        "\n",
        "  def init_hidden(self,shape=1):\n",
        "    return torch.zeros(2, shape, self.hidden_size).to(device)\n",
        "    \n",
        "  def init_cell(self,shape=1):\n",
        "    return torch.zeros(2, shape, self.hidden_size).to(device)\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.i2h = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.i2o = nn.Linear(hidden_size, output_size)\n",
        "      \n",
        "  def forward(self, input, hidden=None, cell=None):\n",
        "    if hidden==None:\n",
        "      hidden = self.init_hidden(input.shape[0])\n",
        "    if cell==None:\n",
        "      cell = self.init_hidden(input.shape[0])\n",
        "\n",
        "    output, (_,_)= self.i2h(input, (hidden,cell))\n",
        "    output = self.dropout(output)\n",
        "    output = self.i2o(output)\n",
        "    output = output[:, -1]\n",
        "    return output\n",
        "\n",
        "  def init_hidden(self,shape=1):\n",
        "    return torch.zeros(1, shape, self.hidden_size)\n",
        "    \n",
        "  def init_cell(self,shape=1):\n",
        "    return torch.zeros(1, shape, self.hidden_size)"
      ],
      "metadata": {
        "id": "06TVEXxQh8KG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# around 90% LSTM for subj/obj\n",
        "lstm = LSTM(word_embedding, n_hidden, n_categories).to(device)\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr = 3e-4)\n",
        "\n",
        "evaluate(lstm, test_loader)\n",
        "\n",
        "for e in range(epochs):\n",
        "  train(lstm, optimizer, train_loader, e)\n",
        "\n",
        "evaluate(lstm, test_loader)"
      ],
      "metadata": {
        "id": "T8YLWc6PlMOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis with LSTM**"
      ],
      "metadata": {
        "id": "CA0DeKIDf0no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "seq_len = 300\n",
        "\n",
        "# corpus_sa_subj contains only subjectivity\n",
        "train_samples_sa_subj, test_samples_sa_subj, train_labels_sa_subj, test_labels_sa_subj = train_test_split(corpus_sa_subj, labels_sa_subj, test_size=0.3, shuffle=True)\n",
        "\n",
        "train_samples_sa_subj = [create_tens(x, seq_len, word_embedding) for x in train_samples_sa_subj]\n",
        "test_samples_sa_subj = [create_tens(x, seq_len, word_embedding) for x in test_samples_sa_subj]\n",
        "\n",
        "train_dataset_sa_subj = Db(train_samples_sa_subj, train_labels_sa_subj)\n",
        "test_dataset_sa_subj = Db(test_samples_sa_subj, test_labels_sa_subj)\n",
        "\n",
        "train_loader_sa_subj = torch.utils.data.DataLoader(train_dataset_sa_subj, batch_size=batch_size, shuffle=True)\n",
        "test_loader_sa_subj = torch.utils.data.DataLoader(test_dataset_sa_subj, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "EWPTWCT2gEJx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 128\n",
        "\n",
        "lstm_sa = LSTM(word_embedding, n_hidden, n_categories)\n",
        "optimizer = torch.optim.Adam(lstm_sa.parameters(), lr = 3e-3, weight_decay=0.001)\n",
        "evaluate(lstm_sa, test_loader_sa_subj)\n",
        "\n",
        "for e in range(epochs):\n",
        "  train(lstm_sa, optimizer, train_loader_sa_subj, e)\n",
        "  evaluate(lstm_sa, test_loader_sa_subj)\n",
        "\n",
        "evaluate(lstm_sa, test_loader_sa_subj)"
      ],
      "metadata": {
        "id": "aAjXCybTgYjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba35880-1e12-41b7-a139-3497b6ba623e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluate accuracy: 48.50: 100%|██████████| 6/6 [00:09<00:00,  1.54s/it]\n",
            "Epoch 1/10, Train accuracy: 53.50: 100%|██████████| 14/14 [01:18<00:00,  5.59s/it]\n",
            "Evaluate accuracy: 62.83: 100%|██████████| 6/6 [00:10<00:00,  1.78s/it]\n",
            "Epoch 2/10, Train accuracy: 72.00: 100%|██████████| 14/14 [00:33<00:00,  2.42s/it]\n",
            "Evaluate accuracy: 61.83: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
            "Epoch 3/10, Train accuracy: 82.43: 100%|██████████| 14/14 [00:23<00:00,  1.66s/it]\n",
            "Evaluate accuracy: 66.50: 100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n",
            "Epoch 4/10, Train accuracy: 88.79: 100%|██████████| 14/14 [00:20<00:00,  1.47s/it]\n",
            "Evaluate accuracy: 67.33: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
            "Epoch 5/10, Train accuracy: 94.14: 100%|██████████| 14/14 [00:30<00:00,  2.15s/it]\n",
            "Evaluate accuracy: 70.17: 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n",
            "Epoch 6/10, Train accuracy: 95.86: 100%|██████████| 14/14 [00:21<00:00,  1.51s/it]\n",
            "Evaluate accuracy: 61.83: 100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n",
            "Epoch 7/10, Train accuracy: 97.43: 100%|██████████| 14/14 [00:22<00:00,  1.62s/it]\n",
            "Evaluate accuracy: 66.67: 100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n",
            "Epoch 8/10, Train accuracy: 98.86: 100%|██████████| 14/14 [00:23<00:00,  1.71s/it]\n",
            "Evaluate accuracy: 70.17: 100%|██████████| 6/6 [00:11<00:00,  1.84s/it]\n",
            "Epoch 9/10, Train accuracy: 99.71: 100%|██████████| 14/14 [00:33<00:00,  2.36s/it]\n",
            "Evaluate accuracy: 70.67: 100%|██████████| 6/6 [00:10<00:00,  1.69s/it]\n",
            "Epoch 10/10, Train accuracy: 99.71: 100%|██████████| 14/14 [00:20<00:00,  1.50s/it]\n",
            "Evaluate accuracy: 70.00: 100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n",
            "Evaluate accuracy: 70.00: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try different LSTM arch\n",
        "lstm_sa_2 = LSTM_2(word_embedding, n_hidden, n_categories)\n",
        "optimizer = torch.optim.Adam(lstm_sa_2.parameters(), lr = 3e-3, weight_decay=0.001)\n",
        "evaluate(lstm_sa_2, test_loader_sa_subj)\n",
        "\n",
        "for e in range(epochs):\n",
        "  train(lstm_sa_2, optimizer, train_loader_sa_subj, e)\n",
        "  evaluate(lstm_sa_2, test_loader_sa_subj)\n",
        "\n",
        "evaluate(lstm_sa_2, test_loader_sa_subj)"
      ],
      "metadata": {
        "id": "pAE04KLM4YQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments:\n",
        "- remove stop words and punctuation\n",
        "- add Sigmoid and 2 more linear layers\n",
        "- try with different sequence length\n",
        "- try with corpus_sa and not corpus_sa_subj: accuracy very bad\n",
        "- Add bidirectional=true in LSTM: first dim of hidden and cell is 2 (instead 1) and self.i2o = nn.Linear(2*hidden_size, 64): 79%\n",
        "- Add a GRU level: 80% con 10 epochs (vedi modello sotto) \n",
        "- Tried RELU + 3 linear linear with 40 epochs 75-80%"
      ],
      "metadata": {
        "id": "EqdPnWwoC-XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing pre-trained DistilBERT model and tokenizer**"
      ],
      "metadata": {
        "id": "DZznxQXv-Skx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tune BERT Model for Sentiment Analysis in Google Colab**\n",
        "https://www.analyticsvidhya.com/blog/2021/12/fine-tune-bert-model-for-sentiment-analysis-in-google-colab/"
      ],
      "metadata": {
        "id": "R4Op5u2n-a8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=8N-nM3QW7O0\n",
        "\n",
        "Papers to cite: Attention is all you need and BERT: pre-training of Deep Bidirectional transformers for Language understanding\n",
        "BERT is bidirectional transformer\n",
        "BERT can be easily fine-tuned to the task\n"
      ],
      "metadata": {
        "id": "0PDnabIo-Yoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "jg5YIIpo-hjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
        "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
        "\n",
        "#Base instead large. Cased considers upper vs lower, uncased not\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)"
      ],
      "metadata": {
        "id": "N-7YPU12-N8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "V4q3HmQW-jpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      truncation=True,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "X8WT1Sx4-uXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 512\n",
        "EPOCHS = 10\n",
        "lr=2e-5\n",
        "categories = 2\n"
      ],
      "metadata": {
        "id": "F4VqydZM-vvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    #returns the last hidden state (_) and the pooled output\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "eZDOI75--wEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  create_data_loader(reviews, targets, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=reviews,\n",
        "    targets=targets,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(ds,batch_size=batch_size,num_workers=2)\n",
        "\n",
        "corpus_sa_subj = [normalizeString(doc2string(p)) for p in pos] + [normalizeString(doc2string(n)) for n in neg]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(corpus_sa_subj, labels_sa_subj)\n",
        "\n",
        "train_data_loader = create_data_loader(train_data, train_labels, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_data, test_labels, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "VSbtDwzW-x6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(categories).to(device)"
      ],
      "metadata": {
        "id": "a8wRhfjc-y6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr, wd=None, momentum=None, opt='Adam'):\n",
        "  if opt == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  elif opt == 'SGD':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "O8VuWfXP-z3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = get_optimizer(model, lr)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "#As in the paper: the lr decreases linearly from the initial lr set in the optimizer to 0\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "VPDt58uG-1FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  samples=0\n",
        "  pbar = tqdm(data_loader)\n",
        "  for d in pbar:\n",
        "    # thanks to dataloader, data are aggregated\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    # to avoid exploding gradient\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    samples += len(d[\"targets\"])\n",
        "    pbar.set_description('Train loss {:.2f} accuracy {:.2f}'.format(np.mean(losses), correct_predictions.double() / samples))"
      ],
      "metadata": {
        "id": "UnLQ0PEw-7qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  samples = 0\n",
        "  pbar = tqdm(data_loader)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in pbar:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "      samples += len(d[\"targets\"])\n",
        "      pbar.set_description('Train loss {:.2f} accuracy {:.2f}'.format(np.mean(losses), correct_predictions.double() / samples))"
      ],
      "metadata": {
        "id": "0rbVkN2Q-8mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on different MAX_LENGTH improves\n",
        "# tried simpler without DataLoader and Dataset but RAM out of memory\n",
        "# with MAX_LENGTH: 350 --> 83.4%\n",
        "#with MAX_LENGTH: 450 and no puctuation --> 86.6 %\n",
        "#with MAX_LENGTH: 512 and no puctuation --> 87.4 %\n",
        "#with MAX_LENGTH: 512, no puctuation and uncasted --> 89 %\n",
        "#with MAX_LENGTH: 512, no puctuation, uncasted and corpus_with_objective(pos + neg) --> \n",
        "%%time \n",
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler\n",
        "  )\n",
        "\n",
        "  test_acc, test_loss = eval_model(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    loss_fn,\n",
        "    device\n",
        "  )\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['test_acc'].append(test_acc)\n",
        "  history['test_loss'].append(test_loss)"
      ],
      "metadata": {
        "id": "XQ1G69QU--dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([s.item() for s in history['train_acc']], label='train accuracy')\n",
        "plt.plot([s.item() for s in history['test_acc']], label='test accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "metadata": {
        "id": "pZEa7sn7-_vH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}