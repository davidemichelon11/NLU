{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidemichelon11/NLU/blob/main/NLU_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfoDANvvOpeO"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import subjectivity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon' )\n",
        "nltk.download('subjectivity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hDlPJeFxfzpH"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DyA5ZMoGjsv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "spacy.cli.download('en_core_web_lg')\n",
        "nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KCS54YCW2vdT"
      },
      "outputs": [],
      "source": [
        "def doc2string(doc):\n",
        "  return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "def sent2string(sent):\n",
        "  return \" \".join([w for w in sent])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI38_yFDSR6s"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "def normalizeString(s):\n",
        "  text_tokens = word_tokenize(s)\n",
        "  s = [word for word in text_tokens if not word in stop_words and not word in punctuation]\n",
        "  s = unicodeToAscii(sent2string(s).lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1yfWeEvbJLeg"
      },
      "outputs": [],
      "source": [
        "test_size=0.2\n",
        "\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]\n",
        "\n",
        "corpus_sub = [normalizeString(sent2string(d[0])) for d in subj_docs] + [normalizeString(sent2string(d[0])) for d in obj_docs]\n",
        "\n",
        "labels_sub = np.array(['subj'] * len(subj_docs) + ['obj'] * len(obj_docs))\n",
        "train_samples_sub, test_samples_sub, train_labels_sub, test_labels_sub = train_test_split(corpus_sub, labels_sub, test_size=test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8oBaoSAM_HW"
      },
      "source": [
        "\n",
        "**Baselines for subjectivity/objectivity detection**\n",
        "\n",
        "Model: *Support Vector Machine*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDE_J5Wjx1V3",
        "outputId": "bc353d9d-0803-4823-a41f-45d09100949e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         obj      0.853     0.916     0.884      1004\n",
            "        subj      0.909     0.841     0.874       996\n",
            "\n",
            "    accuracy                          0.879      2000\n",
            "   macro avg      0.881     0.879     0.879      2000\n",
            "weighted avg      0.881     0.879     0.879      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM for subj/obj detection\n",
        "classifier_SVM_subj = svm.SVC()\n",
        "vectorizer_sub = CountVectorizer()\n",
        "\n",
        "vectors = vectorizer_sub.fit_transform(train_samples_sub + test_samples_sub)\n",
        "\n",
        "#SVM\n",
        "classifier_SVM_subj.fit(vectors[:len(train_samples_sub)], train_labels_sub)\n",
        "labels_pred_SVM = classifier_SVM_subj.predict(vectors[len(train_labels_sub):])\n",
        "print(classification_report(test_labels_sub, labels_pred_SVM, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhxZwaOvaBcl"
      },
      "source": [
        "**Baselines for Seniment Analysis**\n",
        "\n",
        "1.   *SVM with objective sentences*\n",
        "2.   *SVM without objective sentences*\n",
        "3.   *Using VADER on complete review*\n",
        "4.   *Using VADER analyze each sentence*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGeoX7znxAbV"
      },
      "outputs": [],
      "source": [
        "nltk.download('movie_reviews')\n",
        "mr = movie_reviews\n",
        "neg = mr.paras(categories='neg')\n",
        "pos = mr.paras(categories='pos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ewUNWUOvKXPy"
      },
      "outputs": [],
      "source": [
        "vectorizer_sa = CountVectorizer()\n",
        "classifier_sa = svm.SVC()\n",
        "\n",
        "#each element is the review converted to string\n",
        "corpus_sa = [normalizeString(doc2string(p)) for p in pos] + [normalizeString(doc2string(n)) for n in neg]\n",
        "\n",
        "labels_sa = np.array([0] * len(pos) + [1] * len(neg))\n",
        "train_samples_sa, test_samples_sa, train_labels_sa, test_labels_sa = train_test_split(corpus_sa, labels_sa, test_size=test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnx3fdGhcYKX",
        "outputId": "d01263f9-e470-4002-eeb4-ee8ed3278360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.810     0.822     0.816       197\n",
            "           1      0.825     0.813     0.819       203\n",
            "\n",
            "    accuracy                          0.818       400\n",
            "   macro avg      0.818     0.818     0.817       400\n",
            "weighted avg      0.818     0.818     0.818       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM with objective sentences\n",
        "vectors = vectorizer_sa.fit_transform(train_samples_sa + test_samples_sa)\n",
        "classifier_sa.fit(vectors[:len(train_samples_sa)], train_labels_sa)\n",
        "labels_pred = classifier_sa.predict(vectors[len(train_labels_sa):])\n",
        "\n",
        "print(classification_report(test_labels_sa, labels_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i0fw_ujaMF8V"
      },
      "outputs": [],
      "source": [
        "def remove_obj_sentences(reviews, vectorizer_sub):\n",
        "  new_list = []\n",
        "  for rev in reviews:\n",
        "    new_rev = []\n",
        "    for s in rev:\n",
        "      vector = vectorizer_sub.transform([sent2string(s)]).toarray()\n",
        "      if classifier_SVM_subj.predict(vector) == ['subj']: \n",
        "        new_rev.append(s)\n",
        "    new_list.append(new_rev)\n",
        "  return new_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLGRR3-Q7nuS",
        "outputId": "126e7aa5-b492-4d7d-d1b3-b29fc4d78614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.852     0.852     0.852       203\n",
            "           1      0.848     0.848     0.848       197\n",
            "\n",
            "    accuracy                          0.850       400\n",
            "   macro avg      0.850     0.850     0.850       400\n",
            "weighted avg      0.850     0.850     0.850       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For each review, remove obj sentences and compute the SVM\n",
        "vectorizer_sa_subj = CountVectorizer()\n",
        "classifier_SVM_subj_2 = svm.SVC()\n",
        "\n",
        "new_pos = remove_obj_sentences(pos, vectorizer_sub)\n",
        "new_neg = remove_obj_sentences(neg, vectorizer_sub)\n",
        "\n",
        "corpus_sa_subj = [normalizeString(doc2string(p)) for p in new_pos] + [normalizeString(doc2string(n)) for n in new_neg]\n",
        "\n",
        "labels_sa_subj = np.array([0] * len(new_pos) + [1] * len(new_neg))\n",
        "train_samples_, test_samples_, train_labels_, test_labels_ = train_test_split(corpus_sa_subj, labels_sa_subj, test_size=test_size)\n",
        "\n",
        "vectors_ = vectorizer_sa_subj.fit_transform(train_samples_ + test_samples_)\n",
        "classifier_SVM_subj_2.fit(vectors_[:len(train_samples_)], train_labels_)\n",
        "labels_pred_ = classifier_SVM_subj_2.predict(vectors_[len(train_labels_):])\n",
        "\n",
        "print(classification_report(test_labels_, labels_pred_, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAm4UxVFiu4F"
      },
      "source": [
        "**VADER Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6f80ZdAHf5gU"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer, VaderConstants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPUcrVFXkblr",
        "outputId": "4c41297e-83cb-4a16-d037-b2d5fbc43e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.583     0.842     0.689      1000\n",
            "           1      0.715     0.397     0.511      1000\n",
            "\n",
            "    accuracy                          0.620      2000\n",
            "   macro avg      0.649     0.619     0.600      2000\n",
            "weighted avg      0.649     0.620     0.600      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Analyse complete review\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "labels_vader = np.array([0] * len(neg) + [1] * len(pos))\n",
        "prediction_val = [analyzer.polarity_scores(doc2string(v)) for v in (pos + neg)]\n",
        "prediction_labels = [0 if p['pos'] > p['neg'] else 1 for p in prediction_val]\n",
        "\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGLM9GGPSr4h",
        "outputId": "41178552-1eff-42c1-c004-96c3b9ede420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.698     0.500     0.583      1000\n",
            "           1      0.611     0.784     0.687      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.654     0.642     0.635      2000\n",
            "weighted avg      0.654     0.642     0.635      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.602     0.843     0.702      1000\n",
            "           1      0.738     0.442     0.553      1000\n",
            "\n",
            "    accuracy                          0.642      2000\n",
            "   macro avg      0.670     0.642     0.628      2000\n",
            "weighted avg      0.670     0.642     0.628      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Analyse each sentence of review, sum sentences contribution as 1\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += 1\n",
        "    else: neg_ += 1\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))\n",
        "\n",
        "prediction_labels = []\n",
        "\n",
        "for rev in (pos+neg):\n",
        "  pos_ = 0\n",
        "  neg_ = 0\n",
        "  for sent in rev:\n",
        "    p = analyzer.polarity_scores(\" \".join([w for w in sent]))\n",
        "    if p['pos'] > p['neg']: pos_ += p['pos']\n",
        "    else: neg_ += p['neg']\n",
        "  prediction_labels.append(0 if pos_ > neg_ else 1)\n",
        "print(classification_report(labels_sa, prediction_labels, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQLKQjBW62iF"
      },
      "source": [
        "**Objectivity detection using LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-agqb7wb0Jf8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mY-ln6qufjab"
      },
      "outputs": [],
      "source": [
        "batch_size = 120\n",
        "seq_len = 100\n",
        "word_embedding = 300\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "n_categories = 2\n",
        "n_hidden = 256\n",
        "lr = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F_9zUQ9luN_U"
      },
      "outputs": [],
      "source": [
        "class Db(data.Dataset):\n",
        "  def __init__(self, rev, labels):\n",
        "    self.rev = rev\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.rev)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    return torch.tensor(self.rev[idx]), torch.tensor(self.labels[idx])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scheduler(optimizer, epochs, sched='cosine'):\n",
        "  if sched == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "  \n",
        "  return scheduler\n",
        "\n",
        "def get_optimizer(model, lr, wd=0, momentum=0, opt='Adam'):\n",
        "  if opt == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  elif opt == 'SGD':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  \n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "lZF2clSWAl3G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rpnC4z92-Cki"
      },
      "outputs": [],
      "source": [
        "def create_tens(rev, seq_len, word_embedding):\n",
        "  \n",
        "  rev = word_tokenize(rev)\n",
        "  if len(rev) > seq_len: \n",
        "    rev = rev[:seq_len]\n",
        "\n",
        "  sent = []\n",
        "  for i, w in enumerate(rev):\n",
        "    vector = nlp.vocab[w].vector\n",
        "    sent.append(vector.tolist())\n",
        "  \n",
        "  z = list(np.zeros(word_embedding, dtype=np.float32))\n",
        "  zs = [z for each in range(seq_len - len(sent))]\n",
        "  return zs + sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4yYFIJRRPEKt"
      },
      "outputs": [],
      "source": [
        "labels = np.append(np.zeros((len(subj_docs)), dtype=int), np.ones((len(subj_docs)), dtype=int))\n",
        "\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(corpus_sub, labels, test_size=test_size)\n",
        "\n",
        "train_samples = [create_tens(rev, seq_len, word_embedding) for rev in train_samples]\n",
        "test_samples = [create_tens(rev, seq_len, word_embedding) for rev in test_samples]\n",
        "\n",
        "# train samples are tensors of seq_len x word_embedding\n",
        "train_dataset = Db(train_samples, train_labels)\n",
        "test_dataset = Db(test_samples, test_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J196nAnrEXhg"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "def train(model, optimizer, train_loader, e):\n",
        "\n",
        "  cumulative_accuracy = 0\n",
        "  samples=0\n",
        "  pbar = tqdm(train_loader)\n",
        "  for x,y in pbar:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.long())\n",
        "    _, predicted = outputs.max(1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    samples += x.shape[0]\n",
        "    cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "    pbar.set_description('Epoch {}/{}, Train accuracy: {:.3f}'.format(e+1,epochs, cumulative_accuracy/samples))\n",
        "  return cumulative_accuracy/samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XIYsC8uDEYAx"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "\n",
        "  cumulative_accuracy = 0\n",
        "  samples=0\n",
        "  pbar = tqdm(test_loader)\n",
        "  for x,y in pbar:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.long())\n",
        "    _, predicted = outputs.max(1)\n",
        "    samples += x.shape[0]\n",
        "    cumulative_accuracy += predicted.eq(y).sum().item()\n",
        "    pbar.set_description('Evaluate accuracy: {:.3f}'.format(cumulative_accuracy/samples))\n",
        "  return cumulative_accuracy/samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "06TVEXxQh8KG"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.i2h = nn.LSTM(input_size, hidden_size, num_layers=2, dropout = 0.5, bidirectional=True, batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.leaky_ReLU = nn.LeakyReLU(0.1)\n",
        "    self.i2o = nn.Linear(2*hidden_size, output_size)\n",
        "      \n",
        "  def forward(self, input, hidden=None, cell=None):\n",
        "    if hidden==None:\n",
        "      hidden = self.init_hidden(input.shape[0])\n",
        "    if cell==None:\n",
        "      cell = self.init_hidden(input.shape[0])\n",
        "\n",
        "    output, (_,_)= self.i2h(input, (hidden,cell))\n",
        "    output = self.dropout(output)\n",
        "    output = self.i2o(output)\n",
        "    output = self.leaky_ReLU(output)\n",
        "    output = output[:, -1]\n",
        "    return output\n",
        "\n",
        "  def init_hidden(self,shape=1):\n",
        "    return torch.zeros(2*2, shape, self.hidden_size).to(device)\n",
        "    \n",
        "  def init_cell(self,shape=1):\n",
        "    return torch.zeros(2, shape, self.hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(word_embedding, n_hidden, n_categories).to(device)\n",
        "optimizer = get_optimizer(lstm, lr)\n",
        "scheduler = get_scheduler(optimizer, epochs)\n",
        "\n",
        "for e in range(epochs):\n",
        "  train_acc = train(lstm, optimizer, train_loader, e)\n",
        "  test_acc = evaluate(lstm, test_loader)\n",
        "  scheduler.step()\n",
        "evaluate(lstm, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgMh4eNqxXv4",
        "outputId": "b203a2b6-a960-4c61-ceec-089785db9095"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10, Train accuracy: 0.827: 100%|██████████| 67/67 [00:43<00:00,  1.53it/s]\n",
            "Evaluate accuracy: 0.876: 100%|██████████| 17/17 [00:10<00:00,  1.64it/s]\n",
            "Epoch 2/10, Train accuracy: 0.903: 100%|██████████| 67/67 [00:40<00:00,  1.65it/s]\n",
            "Evaluate accuracy: 0.896: 100%|██████████| 17/17 [00:09<00:00,  1.83it/s]\n",
            "Epoch 3/10, Train accuracy: 0.932: 100%|██████████| 67/67 [00:40<00:00,  1.67it/s]\n",
            "Evaluate accuracy: 0.896: 100%|██████████| 17/17 [00:09<00:00,  1.83it/s]\n",
            "Epoch 4/10, Train accuracy: 0.959: 100%|██████████| 67/67 [00:41<00:00,  1.62it/s]\n",
            "Evaluate accuracy: 0.889: 100%|██████████| 17/17 [00:09<00:00,  1.84it/s]\n",
            "Epoch 5/10, Train accuracy: 0.971: 100%|██████████| 67/67 [00:41<00:00,  1.60it/s]\n",
            "Evaluate accuracy: 0.894: 100%|██████████| 17/17 [00:09<00:00,  1.81it/s]\n",
            "Epoch 6/10, Train accuracy: 0.983: 100%|██████████| 67/67 [00:40<00:00,  1.66it/s]\n",
            "Evaluate accuracy: 0.912: 100%|██████████| 17/17 [00:10<00:00,  1.65it/s]\n",
            "Epoch 7/10, Train accuracy: 0.993: 100%|██████████| 67/67 [00:40<00:00,  1.65it/s]\n",
            "Evaluate accuracy: 0.912: 100%|██████████| 17/17 [00:09<00:00,  1.84it/s]\n",
            "Epoch 8/10, Train accuracy: 0.995: 100%|██████████| 67/67 [00:40<00:00,  1.67it/s]\n",
            "Evaluate accuracy: 0.905: 100%|██████████| 17/17 [00:09<00:00,  1.83it/s]\n",
            "Epoch 9/10, Train accuracy: 0.995: 100%|██████████| 67/67 [00:41<00:00,  1.63it/s]\n",
            "Evaluate accuracy: 0.904: 100%|██████████| 17/17 [00:09<00:00,  1.84it/s]\n",
            "Epoch 10/10, Train accuracy: 0.996: 100%|██████████| 67/67 [00:40<00:00,  1.67it/s]\n",
            "Evaluate accuracy: 0.908: 100%|██████████| 17/17 [00:09<00:00,  1.84it/s]\n",
            "Evaluate accuracy: 0.903: 100%|██████████| 17/17 [00:09<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9035"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Op5u2n-a8r"
      },
      "source": [
        "**Fine-tune BERT Model for Sentiment Analysis in Google Colab**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg5YIIpo-hjZ"
      },
      "outputs": [],
      "source": [
        "# ! pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-7YPU12-N8V"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers as ppb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X8WT1Sx4-uXZ"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      truncation=True,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F4VqydZM-vvB"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eZDOI75--wEd"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    #returns the last hidden state (_) and the pooled output\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "_tKK_UeXdI0G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VSbtDwzW-x6Q"
      },
      "outputs": [],
      "source": [
        "def  create_data_loader(reviews, targets, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=reviews,\n",
        "    targets=targets,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(ds,batch_size=batch_size,num_workers=2)\n",
        "  \n",
        "corpus_sa_subj = [normalizeString(doc2string(p)) for p in pos] + [normalizeString(doc2string(n)) for n in neg]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(corpus_sa_subj, labels_sa_subj)\n",
        "\n",
        "train_data_loader = create_data_loader(train_data, train_labels, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_data, test_labels, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8wRhfjc-y6x"
      },
      "outputs": [],
      "source": [
        "categories = 2\n",
        "model = SentimentClassifier(categories).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VPDt58uG-1FP"
      },
      "outputs": [],
      "source": [
        "optimizer = get_optimizer(model, lr)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_data_loader) * epochs\n",
        "\n",
        "#As in the paper: the lr decreases linearly from the initial lr set in the optimizer to 0\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UnLQ0PEw-7qH"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    # thanks to dataloader, data are aggregated\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    # to avoid exploding gradient\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0rbVkN2Q-8mz"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device,n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XQ1G69QU--dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20e6f2c-7bba-446b-8048-a4c860d01925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train loss 0.666 Train accuracy 0.562 \n",
            "Test loss 0.437 Test accuracy 0.820 \n",
            "----------\n",
            "Epoch 2/10\n",
            "Train loss 0.425 Train accuracy 0.825 \n",
            "Test loss 0.354 Test accuracy 0.856 \n",
            "----------\n",
            "Epoch 3/10\n",
            "Train loss 0.267 Train accuracy 0.905 \n",
            "Test loss 0.408 Test accuracy 0.872 \n",
            "----------\n",
            "Epoch 4/10\n",
            "Train loss 0.130 Train accuracy 0.965 \n",
            "Test loss 0.635 Test accuracy 0.884 \n",
            "----------\n",
            "Epoch 5/10\n",
            "Train loss 0.076 Train accuracy 0.983 \n",
            "Test loss 0.723 Test accuracy 0.840 \n",
            "----------\n",
            "Epoch 6/10\n",
            "Train loss 0.054 Train accuracy 0.986 \n",
            "Test loss 0.583 Test accuracy 0.882 \n",
            "----------\n",
            "Epoch 7/10\n",
            "Train loss 0.045 Train accuracy 0.991 \n",
            "Test loss 0.541 Test accuracy 0.894 \n",
            "----------\n",
            "Epoch 8/10\n",
            "Train loss 0.016 Train accuracy 0.997 \n",
            "Test loss 0.577 Test accuracy 0.892 \n",
            "----------\n",
            "Epoch 9/10\n",
            "Train loss 0.017 Train accuracy 0.997 \n",
            "Test loss 0.589 Test accuracy 0.896 \n",
            "----------\n",
            "Epoch 10/10\n",
            "Train loss 0.013 Train accuracy 0.998 \n",
            "Test loss 0.602 Test accuracy 0.890 \n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(epochs):\n",
        "  print(f'Epoch {epoch + 1}/{epochs}')\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(train_data)\n",
        "  )\n",
        "  print('Train loss {:.3f} Train accuracy {:.3f} '.format(train_loss, train_acc))\n",
        "\n",
        "  test_acc, test_loss = eval_model(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(test_data)\n",
        "  )\n",
        "  print('Test loss {:.3f} Test accuracy {:.3f} '.format(test_loss, test_acc))\n",
        "\n",
        "  print('-' * 10)\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['test_acc'].append(test_acc)\n",
        "  history['test_loss'].append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pZEa7sn7-_vH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "91bc404d-0ce3-4bc9-bf3c-7816fd6fcb5f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot([s.item() for s in history['train_acc']], label='train accuracy')\n",
        "plt.plot([s.item() for s in history['test_acc']], label='test accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.5, 1]);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLU_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOq7s1fuCocaat5Ed+zsPMJ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}